/*! For license information please see becd9658.39637ba1.js.LICENSE.txt */
"use strict";(self.webpackChunkwebsite_docusaurus=self.webpackChunkwebsite_docusaurus||[]).push([[883],{3490:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>t,default:()=>h,frontMatter:()=>i,metadata:()=>d,toc:()=>l});var s=r(4848),a=r(8453);const i={},t="How Rendering Works",d={id:"api-guide/gpu/gpu-rendering",title:"How Rendering Works",description:"Applications will typically used the Model class in @luma.gl/engine module to issue draw calls.",source:"@site/../docs/api-guide/gpu/gpu-rendering.md",sourceDirName:"api-guide/gpu",slug:"/api-guide/gpu/gpu-rendering",permalink:"/docs/api-guide/gpu/gpu-rendering",draft:!1,unlisted:!1,editUrl:"https://github.com/visgl/luma.gl/tree/main/docs/../docs/api-guide/gpu/gpu-rendering.md",tags:[],version:"current",frontMatter:{},sidebar:"sidebar",previous:{title:"Using GPU Textures",permalink:"/docs/api-guide/gpu/gpu-textures"},next:{title:"Using GPU Parameters",permalink:"/docs/api-guide/gpu/gpu-parameters"}},c={},l=[{value:"Creating a RenderPipeline",id:"creating-a-renderpipeline",level:3},{value:"Drawing",id:"drawing",level:3},{value:"Transform Feedback (WebGL)",id:"transform-feedback-webgl",level:3},{value:"Rendering into a canvas",id:"rendering-into-a-canvas",level:2},{value:"Clearing the screen",id:"clearing-the-screen",level:2},{value:"Offscreen rendering",id:"offscreen-rendering",level:2},{value:"Framebuffer Attachments",id:"framebuffer-attachments",level:2},{value:"Resizing Framebuffers",id:"resizing-framebuffers",level:2},{value:"Using Multiple Render Targets",id:"using-multiple-render-targets",level:3}];function o(e){const n={admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"how-rendering-works",children:"How Rendering Works"}),"\n",(0,s.jsx)(n.admonition,{type:"info",children:(0,s.jsxs)(n.p,{children:["Applications will typically used the ",(0,s.jsx)(n.code,{children:"Model"})," class in ",(0,s.jsx)(n.code,{children:"@luma.gl/engine"})," module to issue draw calls.\nWhile the ",(0,s.jsx)(n.code,{children:"Model"})," class handles some of the necessary setup, it is still useful to understand how\nrendering is done with the underlying ",(0,s.jsx)(n.code,{children:"Renderpipeline"})]})}),"\n",(0,s.jsx)(n.p,{children:"A major feature of any GPU API is the ability to issue GPU draw calls. luma.gl has been designed to offer developers full control over draw calls as outlined below."}),"\n",(0,s.jsx)(n.p,{children:"Note that the luma.gl documentation includes a series of tutorials that explain how to render with the luma.gl API."}),"\n",(0,s.jsx)(n.h3,{id:"creating-a-renderpipeline",children:"Creating a RenderPipeline"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const pipeline = device.createRenderPipeline({\n  id: 'my-pipeline',\n  vs: vertexShaderSourceString,\n  fs: fragmentShaderSourceString\n});\n"})}),"\n",(0,s.jsx)(n.p,{children:"Set or update uniforms, in this case world and projection matrices"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"pipeline.setUniforms({\n  uMVMatrix: view,\n  uPMatrix: projection\n});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"drawing",children:"Drawing"}),"\n",(0,s.jsxs)(n.p,{children:["Once all bindings have been set up, call ",(0,s.jsx)(n.code,{children:"pipeline.draw()"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const pipeline = device.createRenderPipeline({vs, fs});\n\n// Create a `VertexArray` to store buffer values for the vertices of a triangle and drawing\nconst vertexArray = device.createVertexArray();\n...\n\nconst success = pipeline.draw({vertexArray, ...});\n"})}),"\n",(0,s.jsx)(n.h3,{id:"transform-feedback-webgl",children:"Transform Feedback (WebGL)"}),"\n",(0,s.jsx)(n.p,{children:"Creating a pipeline for transform feedback, specifying which varyings to use"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const pipeline = device.createRenderPipeline({vs, fs, varyings: ['gl_Position']});\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"\nSet or update uniforms, in this case world and projection matrices\n\n```typescript\npipeline.setUniforms({\n  uMVMatrix: view,\n  uPMatrix: projection\n});\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Create a ",(0,s.jsx)(n.code,{children:"VertexArray"})," to store buffer values for the vertices of a triangle and drawing"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const pipeline = device.createRenderPipeline({vs, fs});\n\nconst vertexArray = new VertexArray(gl, {pipeline});\n\nvertexArray.setAttributes({\n  aVertexPosition: new Buffer(gl, {data: new Float32Array([0, 1, 0, -1, -1, 0, 1, -1, 0])})\n});\n\npipeline.draw({vertexArray, ...});\n"})}),"\n",(0,s.jsx)(n.p,{children:"Creating a pipeline for transform feedback, specifying which varyings to use"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const pipeline = device.createRenderPipeline({vs, fs, varyings: ['gl_Position']});\n"})}),"\n",(0,s.jsx)(n.h2,{id:"rendering-into-a-canvas",children:"Rendering into a canvas"}),"\n",(0,s.jsxs)(n.p,{children:["To render to the screen requires rendering into a canvas, a special ",(0,s.jsx)(n.code,{children:"Framebuffer"})," should be obtained from a\n",(0,s.jsx)(n.code,{children:"CanvasContext"})," using ",(0,s.jsx)(n.code,{children:"canvasContext.getDefaultFramebuffer()"}),".\nA device context ",(0,s.jsx)(n.code,{children:"Framebuffer"})," and has a (single) special color attachment that is connected to the\ncurrent swap chain buffer, and also a depth buffer, and is automatically resized to match the size of the canvas\nassociated."]}),"\n",(0,s.jsxs)(n.p,{children:["To draw to the screen in luma.gl, simply create a ",(0,s.jsx)(n.code,{children:"RenderPass"})," by calling\n",(0,s.jsx)(n.code,{children:"device.beginRenderPass()"})," and start rendering. When done rendering, call\n",(0,s.jsx)(n.code,{children:"renderPass.end()"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"  // A renderpass without parameters uses the default framebuffer of the device's default CanvasContext \n  const renderPass = device.beginRenderPass();\n  model.draw();\n  renderPass.end();\n  device.submit(); \n"})}),"\n",(0,s.jsxs)(n.p,{children:["For more detail. ",(0,s.jsx)(n.code,{children:"device.canvasContext.getDefaultFramebuffer()"})," returns a special framebuffer that lets you render to screen (into the device's swap chain textures). This framebuffer is used by default when a ",(0,s.jsx)(n.code,{children:"device.beginRenderPass()"})," is called without providing a ",(0,s.jsx)(n.code,{children:"framebuffer"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"  const renderPass = device.beginRenderPass({framebuffer: device.canvasContext.getDefaultFramebuffer()});\n  ...\n"})}),"\n",(0,s.jsx)(n.h2,{id:"clearing-the-screen",children:"Clearing the screen"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Framebuffer"})," attachments are cleared by default when a RenderPass starts. Control is provided via the ",(0,s.jsx)(n.code,{children:"RenderPassProps.clearColor"})," parameter, setting this will clear the attachments to the corresponding color. The default clear color is a fully transparent black ",(0,s.jsx)(n.code,{children:"[0, 0, 0, 0]"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"  const renderPass = device.beginRenderPass({clearColor: [0, 0, 0, 1]});\n  model.draw();\n  renderPass.end();\n  device.submit();\n"})}),"\n",(0,s.jsx)(n.p,{children:"Depth and stencil buffers are also cleared to default values:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"  const renderPass = device.beginRenderPass({\n    clearColor: [0, 0, 0, 1],\n    depthClearValue: 1,\n    stencilClearValue: 0\n  });\n  renderPass.end();\n  device.submit();\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Clearing can  be disabled by setting any of the clear properties to the string constant ",(0,s.jsx)(n.code,{children:"'load'"}),". Instead of clearing before rendering, this loads the previous contents of the framebuffer. Clearing should generally be expected to be more performant."]}),"\n",(0,s.jsx)(n.h2,{id:"offscreen-rendering",children:"Offscreen rendering"}),"\n",(0,s.jsxs)(n.p,{children:["While is possible to render into an ",(0,s.jsx)(n.code,{children:"OffscreenCanvas"}),", offscreen rendering usually refers to\nrendering into one or more application created ",(0,s.jsx)(n.code,{children:"Texture"}),"s."]}),"\n",(0,s.jsxs)(n.p,{children:["To help organize and resize these textures, luma.gl provides a ",(0,s.jsx)(n.code,{children:"Framebuffer"})," class.\nA ",(0,s.jsx)(n.code,{children:"Framebuffer"})," is a simple container object that holds textures that will be used as render targets for a ",(0,s.jsx)(n.code,{children:"RenderPass"}),", containing"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"one or more color attachments"}),"\n",(0,s.jsx)(n.li,{children:"optionally, a depth, stencil or depth-stencil attachment"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"Framebuffer"})," also provides a ",(0,s.jsx)(n.code,{children:"resize"})," method makes it easy to efficiently resize all the attachments of a ",(0,s.jsx)(n.code,{children:"Framebuffer"})," with a single method call."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"device.createFramebuffer"})," constructor enables the creation of a framebuffer with all attachments in a single step."]}),"\n",(0,s.jsxs)(n.p,{children:["When no attachments are provided during ",(0,s.jsx)(n.code,{children:"Framebuffer"})," object creation, new resources are created and used as default attachments for enabled targets (color and depth)."]}),"\n",(0,s.jsxs)(n.p,{children:["For color, new ",(0,s.jsx)(n.code,{children:"Texture2D"})," object is created with no mipmaps and following filtering parameters are set."]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Texture parameter"}),(0,s.jsx)(n.th,{children:"Value"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"minFilter"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"linear"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"magFilter"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"linear"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"addressModeU"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"clamp-to-edge"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"addressModeV"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"clamp-to-edge"})})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:["An application can render into an (HTML or offscreen) canvas by obtaining a\n",(0,s.jsx)(n.code,{children:"Framebuffer"})," object from a ",(0,s.jsx)(n.code,{children:"CanvasContext"})," using ",(0,s.jsx)(n.code,{children:"canvasContext.getDefaultFramebuffer()"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Alternatively an application can create custom framebuffers for rendering directly into textures."}),"\n",(0,s.jsxs)(n.p,{children:["The application uses a ",(0,s.jsx)(n.code,{children:"Framebuffer"})," by providing it as a parameter to ",(0,s.jsx)(n.code,{children:"device.beginRenderPass()"}),".\nAll operations on that ",(0,s.jsx)(n.code,{children:"RenderPass"})," instance will render into that framebuffer."]}),"\n",(0,s.jsxs)(n.p,{children:["A ",(0,s.jsx)(n.code,{children:"Framebuffer"}),' is shallowly immutable (the list of attachments cannot be changed after creation),\nhowever a Framebuffer can be "resized".']}),"\n",(0,s.jsx)(n.h2,{id:"framebuffer-attachments",children:"Framebuffer Attachments"}),"\n",(0,s.jsxs)(n.p,{children:["A ",(0,s.jsx)(n.code,{children:"Framebuffer"})," holds:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:['an array of "color attachments" (often just one) that store data (one or more color ',(0,s.jsx)(n.code,{children:"Texture"}),"s)"]}),"\n",(0,s.jsxs)(n.li,{children:["an optional depth, stencil or combined depth-stencil ",(0,s.jsx)(n.code,{children:"Texture"}),")."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["All attachments must be in the form of ",(0,s.jsx)(n.code,{children:"Texture"}),"s."]}),"\n",(0,s.jsx)(n.h2,{id:"resizing-framebuffers",children:"Resizing Framebuffers"}),"\n",(0,s.jsx)(n.p,{children:"Resizing a framebuffer effectively destroys all current textures and creates new\ntextures with otherwise similar properties. All data stored in the previous textures are lost.\nThis data loss is usually a non-issue as resizes are usually performed between render passes,\n(typically to match the size of an off screen render buffer with the new size of the output canvas)."}),"\n",(0,s.jsx)(n.p,{children:"A default Framebuffer should not be manually resized."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const framebuffer = device.createFramebuffer({\n  width: window.innerWidth,\n  height: window.innerHeight,\n  color: 'true',\n  depthStencil: true\n});\n"})}),"\n",(0,s.jsx)(n.p,{children:"Attaching textures and renderbuffers"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"device.createFramebuffer({\n  depthStencil: device.createRenderbuffer({...}),\n  color0: device.createTexture({...})\n});\nframebuffer.checkStatus(); // optional\n"})}),"\n",(0,s.jsx)(n.p,{children:"Resizing a framebuffer to the size of a window. Resizes (and possibly clears) all attachments."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"framebuffer.resize(window.innerWidth, window.innerHeight);\n"})}),"\n",(0,s.jsx)(n.p,{children:"Specifying a framebuffer for rendering in each render calls"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const offScreenBuffer = device.createFramebuffer(...);\nconst offScreenRenderPass = device.beginRenderPass({framebuffer: offScreenFramebuffer});\nmodel1.draw({\n  framebuffer: offScreenBuffer,\n  parameters: {}\n});\nmodel2.draw({\n  framebuffer: null, // the default drawing buffer\n  parameters: {}\n});\n"})}),"\n",(0,s.jsx)(n.p,{children:"Clearing a framebuffer"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"framebuffer.clear();\nframebuffer.clear({color: [0, 0, 0, 0], depth: 1, stencil: 0});\n"})}),"\n",(0,s.jsx)(n.p,{children:"Binding a framebuffer for multiple render calls"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-typescript",children:"const framebuffer1 = device.createFramebuffer({...});\nconst framebuffer2 = device.createFramebuffer({...});\n\nconst renderPass1 = device.beginRenderPass({framebuffer: framebuffer1});\nprogram.draw(renderPass1);\nrenderPass1.endPass();\n\nconst renderPass2 = device.beginRenderPass({framebuffer: framebuffer1});\nprogram.draw(renderPass2);\nrenderPass2.endPass();\n"})}),"\n",(0,s.jsx)(n.h3,{id:"using-multiple-render-targets",children:"Using Multiple Render Targets"}),"\n",(0,s.jsx)(n.p,{children:"The colorAttachments can be referenced in the shaders"}),"\n",(0,s.jsx)(n.p,{children:"Writing to multiple framebuffer attachments in GLSL fragment shader"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"#extension GL_EXT_draw_buffers : require\nprecision highp float;\nvoid main(void) {\n  gl_FragData[0] = vec4(0.25);\n  gl_FragData[1] = vec4(0.5);\n  gl_FragData[2] = vec4(0.75);\n  gl_FragData[3] = vec4(1.0);\n}\n"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},1020:(e,n,r)=>{var s=r(6540),a=Symbol.for("react.element"),i=Symbol.for("react.fragment"),t=Object.prototype.hasOwnProperty,d=s.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,c={key:!0,ref:!0,__self:!0,__source:!0};function l(e,n,r){var s,i={},l=null,o=null;for(s in void 0!==r&&(l=""+r),void 0!==n.key&&(l=""+n.key),void 0!==n.ref&&(o=n.ref),n)t.call(n,s)&&!c.hasOwnProperty(s)&&(i[s]=n[s]);if(e&&e.defaultProps)for(s in n=e.defaultProps)void 0===i[s]&&(i[s]=n[s]);return{$$typeof:a,type:e,key:l,ref:o,props:i,_owner:d.current}}n.Fragment=i,n.jsx=l,n.jsxs=l},4848:(e,n,r)=>{e.exports=r(1020)},8453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>d});var s=r(6540);const a={},i=s.createContext(a);function t(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:t(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);